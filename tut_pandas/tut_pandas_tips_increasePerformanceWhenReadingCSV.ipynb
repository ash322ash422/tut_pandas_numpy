{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1e51c23-e56a-4b95-92c9-981a23cae3ab",
   "metadata": {},
   "source": [
    "# Pandas CSV Reading Performance Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7371ccb4",
   "metadata": {},
   "source": [
    "## Following code would generate data_file and then we would use this file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef393cb9-4a96-46b8-ae85-eaee199908a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "data_file = 'junk_data_read_performance.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb39826f-aeab-460f-acff-8ff7605a3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample dataset 'data_read_perfomance.csv' with 10000000 rows created successfully!\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Took 1 minute to generate the CSB file\n",
    "\n",
    "# Lets generate some fake data and save to a csv file for testing:\n",
    "\n",
    "# Number of rows\n",
    "n = 10000000\n",
    "\n",
    "# Random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate data\n",
    "data = {\n",
    "    \"id\": np.arange(1, n + 1, dtype=\"int32\"),\n",
    "    \"name\": np.random.choice([\"Fernando\", \"Prakash\", \"Shamlodhiya\", \"Smith\", \"Patel\", \"Juno\"], size=n),\n",
    "    \"amount\": np.round(np.random.uniform(50, 500, size=n), 2).astype(\"float32\"),\n",
    "    \"status\": np.random.choice([\"Paid\", \"Pending\", \"Failed\"], size=n, p=[0.6, 0.3, 0.1])\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save as CSV\n",
    "df.to_csv(data_file, index=False)\n",
    "\n",
    "print(f\"Sample dataset '{data_file}' with {n} rows created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4a3ec-0efe-4ef0-9b35-5581f7a2a352",
   "metadata": {},
   "source": [
    "## 1. Use dtype to specify column types\n",
    "- Avoid pandas guessing data\n",
    "- The process is slower but is memory efficient\n",
    "- Define dtypes for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "693fa718-0549-47e8-9d52-7e4d30abdb31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         name  amount  status\n",
      "0   1        Smith  282.05    Paid\n",
      "1   2        Patel  355.10    Paid\n",
      "2   3  Shamlodhiya  164.49  Failed\n",
      "3   4        Patel  122.70  Failed\n",
      "4   5        Patel   82.75    Paid\n",
      "3.890625\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   name    object \n",
      " 2   amount  float64\n",
      " 3   status  object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Took 4 secs\n",
    "# step1: Without specifying dtypes\n",
    "\n",
    "start = time.process_time()\n",
    "df = pd.read_csv(data_file)\n",
    "end = time.process_time()\n",
    "\n",
    "print(df.head())\n",
    "print(end - start)\n",
    "print(df.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16538a4c-e485-4f78-ae86-289b98717708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         name      amount  status\n",
      "0   1        Smith  282.049988    Paid\n",
      "1   2        Patel  355.100006    Paid\n",
      "2   3  Shamlodhiya  164.490005  Failed\n",
      "3   4        Patel  122.699997  Failed\n",
      "4   5        Patel   82.750000    Paid\n",
      "4.234375\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype   \n",
      "---  ------  -----   \n",
      " 0   id      int32   \n",
      " 1   name    category\n",
      " 2   amount  float32 \n",
      " 3   status  category\n",
      "dtypes: category(2), float32(1), int32(1)\n",
      "memory usage: 95.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# NOTE: Took 4.2 secs\n",
    "# step2: with dtype explicitly mentioned\n",
    "\n",
    "dtypes = {\n",
    "    'id': 'int32',\n",
    "    'name': 'category',\n",
    "    'amount': 'float32',\n",
    "    'status': 'category'\n",
    "}\n",
    "start = time.process_time()\n",
    "df = pd.read_csv(data_file, dtype=dtypes)\n",
    "end = time.process_time()\n",
    "\n",
    "print(df.head())\n",
    "print(end - start)\n",
    "print(df.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d50a63d0-ede8-4fbb-ac1d-051ec3daa468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.626834381551362"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much memry saved ?\n",
    "1300/95.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0acb54-db9e-4230-8077-951afacaa3d2",
   "metadata": {},
   "source": [
    "## conclusion: The process slows down little bit, but you save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f217341-f36e-4a35-aa43-a1934fe2b544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6c9370-751f-4697-bcf9-969ac78db9f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58149954-4607-445a-b96e-81063545b4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410f93fb-d72f-404a-90a7-d6ffa0a24e60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c57adc5-1bca-46d6-a9b5-9172b4a41294",
   "metadata": {},
   "source": [
    "## 2. Use usecols to load only required columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3dda149-9c24-493a-a519-d3ea49c481bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id         name  amount  status\n",
      "0   1        Smith  282.05    Paid\n",
      "1   2        Patel  355.10    Paid\n",
      "2   3  Shamlodhiya  164.49  Failed\n",
      "3   4        Patel  122.70  Failed\n",
      "4   5        Patel   82.75    Paid\n",
      "3.734375\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   name    object \n",
      " 2   amount  float64\n",
      " 3   status  object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 1.3 GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# step1: Read all columns\n",
    "\n",
    "start = time.process_time()\n",
    "df = pd.read_csv(data_file)\n",
    "end = time.process_time()\n",
    "\n",
    "print(df.head())\n",
    "print(end - start)\n",
    "print(df.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "992c3d85-939d-4a38-b1fc-4f1d771ca25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  amount\n",
      "0   1  282.05\n",
      "1   2  355.10\n",
      "2   3  164.49\n",
      "3   4  122.70\n",
      "4   5   82.75\n",
      "3.0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   id      int64  \n",
      " 1   amount  float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 152.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# step2: Read all columns\n",
    "\n",
    "start = time.process_time()\n",
    "df = pd.read_csv(data_file, usecols=['id', 'amount'])\n",
    "end = time.process_time()\n",
    "\n",
    "print(df.head())\n",
    "print(end - start)\n",
    "print(df.info(memory_usage=\"deep\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0df78900-4b28-4969-961f-43e39327b40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.552631578947368"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How much saving in memory\n",
    "1300/152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f34873-cb16-44b7-bef7-24dd2795d0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## conlusion: Helps save memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc72801-c19f-4bef-a176-3073ed782463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba30a4b-3201-48d2-9545-1d443149c44e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b07ea8f-a2a7-40c4-9bdc-04c4076a8717",
   "metadata": {},
   "source": [
    "## 5. Process large files in chunks using chunksize\n",
    "\n",
    "### When to use chunking ?\n",
    "\n",
    "You only need to aggregate results (e.g., sum, mean, counts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ac668a4-d17c-4136-8085-057aa03afe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full load:    sum=247479112, time=0.53 sec\n",
      "Chunked load: sum=247479112, time=0.89 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Create a large CSV (5 million rows)\n",
    "rows = 5_000_000\n",
    "df = pd.DataFrame({\n",
    "    \"id\": np.arange(rows),\n",
    "    \"value\": np.random.randint(0, 100, size=rows)\n",
    "})\n",
    "df.to_csv(\"big_data.csv\", index=False)\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Read at once (memory heavy)\n",
    "start = time.process_time()\n",
    "df_full = pd.read_csv(\"big_data.csv\")\n",
    "total_sum_full = df_full[\"value\"].sum()\n",
    "end = time.process_time()\n",
    "print(f\"Full load:    sum={total_sum_full}, time={end - start:.2f} sec\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Read in chunks (memory light)\n",
    "start = time.process_time()\n",
    "total_sum_chunk = 0\n",
    "chunks = pd.read_csv(\"big_data.csv\", chunksize=100_000)  # 100k rows at a time\n",
    "for chunk in chunks:\n",
    "    total_sum_chunk += chunk[\"value\"].sum()\n",
    "end = time.process_time()\n",
    "print(f\"Chunked load: sum={total_sum_chunk}, time={end - start:.2f} sec\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976d1209-d036-4195-867a-51abf0d098e7",
   "metadata": {},
   "source": [
    "## conlusion\n",
    "- Both methods give the same result\n",
    "- Chunking uses far less memory (youâ€™re only holding 100k rows in memory at any given time instead of 5 million).\n",
    "- The speed may be slightly better or slightly worse depending on system I/O, but the **real win is memory efficiency**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33e6352-07f0-4052-94bb-2153067e5622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e768453-1eb2-47d7-9a46-cd96fad4d9cd",
   "metadata": {},
   "source": [
    "## 7. (NOT CONCLUSIVE): Disable quoting if not needed (speeds up parsing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e0ec068-5953-4c9a-b60d-dd7b707c9826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.984042200000204\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "start = time.perf_counter()\n",
    "df = pd.read_csv(data_file)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "592d15f0-c7c7-461e-a395-c21cb91d3e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.962390000000141\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.perf_counter()\n",
    "df = pd.read_csv(data_file, quoting=csv.QUOTE_NONE)\n",
    "end = time.perf_counter()\n",
    "\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7c9c96-7609-4695-8994-c426bcb87e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbebb1f-70ff-409e-b284-ec31771566b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48c75d-69db-4b9b-a2ad-056e5d14f350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8b399-d399-43d0-a95a-700cea621e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 3. Parse dates efficiently using parse_dates\n",
    "df = pd.read_csv(data_file, parse_dates=['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e613bd51-701c-4f19-9b93-f955c13e76b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8187aef-7d0a-4a01-b6f5-66a6fe1b3d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1866a91-f19c-4ac6-be55-4897baa6654f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a8b3e1-c22b-4349-9083-a32b4890f89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 6. Use compression if reading from zipped files\n",
    "df = pd.read_csv('data.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe06014-3a2c-4a2d-930a-2663cdfac213",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52e700-10af-479f-a19a-c4f353839686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919906de-ed09-4630-8f4a-6ea7a638791f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f06d07fd-0d41-45ea-9e6e-c899c336e00e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ## 8. Use faster backend engines (pandas 2.0+)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Alternative to engine='c'\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:624\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    623\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1909\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1907\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1908\u001b[0m         \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m-> 1909\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m   1910\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1911\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\arrow_parser_wrapper.py:244\u001b[0m, in \u001b[0;36mArrowParserWrapper.read\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;124;03m    Reads the contents of a CSV file into a DataFrame and\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    processes it according to the kwargs passed in the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m        The DataFrame created from the CSV file.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 244\u001b[0m     pa \u001b[38;5;241m=\u001b[39m \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    245\u001b[0m     pyarrow_csv \u001b[38;5;241m=\u001b[39m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pyarrow_options()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'.  Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "# ## 8. Use faster backend engines (pandas 2.0+)\n",
    "df = pd.read_csv(data_file, engine='pyarrow')  # Alternative to engine='c'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79c1592-5705-4e7d-ac63-a9fda31fe759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
