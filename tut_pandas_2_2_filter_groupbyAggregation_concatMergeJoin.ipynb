{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2ffbad3-8eac-4b42-95cb-7c3fbda71af2",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "Topics covered:\n",
    "- filtering\n",
    "- groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9862a0c-15e8-4200-beb2-101cdf84777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Suppress all FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3071d15-edab-4787-94da-fe190b2fca30",
   "metadata": {},
   "source": [
    "### filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efb80c28-baaa-4b6d-828c-fe05e8ceb259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
      "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
      "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "0    man        True  NaN  Southampton    no  False  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "4    man        True  NaN  Southampton    no   True  \n",
      "\n",
      "Female survivors:\n",
      "   survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "1         1       1  female  38.0      1      0  71.2833        C   First   \n",
      "2         1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "3         1       1  female  35.0      1      0  53.1000        S   First   \n",
      "8         1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9         1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "\n",
      "     who  adult_male deck  embark_town alive  alone  \n",
      "1  woman       False    C    Cherbourg   yes  False  \n",
      "2  woman       False  NaN  Southampton   yes   True  \n",
      "3  woman       False    C  Southampton   yes  False  \n",
      "8  woman       False  NaN  Southampton   yes  False  \n",
      "9  child       False  NaN    Cherbourg   yes  False  \n",
      "11111111111111111111111111\n",
      "\n",
      "First class or elderly passengers:\n",
      "    survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
      "1          1       1  female  38.0      1      0  71.2833        C  First   \n",
      "3          1       1  female  35.0      1      0  53.1000        S  First   \n",
      "6          0       1    male  54.0      0      0  51.8625        S  First   \n",
      "11         1       1  female  58.0      0      0  26.5500        S  First   \n",
      "23         1       1    male  28.0      0      0  35.5000        S  First   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "1   woman       False    C    Cherbourg   yes  False  \n",
      "3   woman       False    C  Southampton   yes  False  \n",
      "6     man        True    E  Southampton    no   True  \n",
      "11  woman       False    C  Southampton   yes   True  \n",
      "23    man        True    A  Southampton   yes   True  \n",
      "22222222222222222222222222\n",
      "\n",
      "Young male non-survivors:\n",
      "    survived  pclass   sex   age  sibsp  parch     fare embarked  class  \\\n",
      "7          0       3  male   2.0      3      1  21.0750        S  Third   \n",
      "16         0       3  male   2.0      4      1  29.1250        Q  Third   \n",
      "50         0       3  male   7.0      4      1  39.6875        S  Third   \n",
      "59         0       3  male  11.0      5      2  46.9000        S  Third   \n",
      "63         0       3  male   4.0      3      2  27.9000        S  Third   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "7   child       False  NaN  Southampton    no  False  \n",
      "16  child       False  NaN   Queenstown    no  False  \n",
      "50  child       False  NaN  Southampton    no  False  \n",
      "59  child       False  NaN  Southampton    no  False  \n",
      "63  child       False  NaN  Southampton    no  False  \n",
      "3333333333333333333333333333333333\n",
      "\n",
      "Females in 2nd or 3rd class:\n",
      "    survived  pclass     sex   age  sibsp  parch     fare embarked   class  \\\n",
      "2          1       3  female  26.0      0      0   7.9250        S   Third   \n",
      "8          1       3  female  27.0      0      2  11.1333        S   Third   \n",
      "9          1       2  female  14.0      1      0  30.0708        C  Second   \n",
      "10         1       3  female   4.0      1      1  16.7000        S   Third   \n",
      "14         0       3  female  14.0      0      0   7.8542        S   Third   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "2   woman       False  NaN  Southampton   yes   True  \n",
      "8   woman       False  NaN  Southampton   yes  False  \n",
      "9   child       False  NaN    Cherbourg   yes  False  \n",
      "10  child       False    G  Southampton   yes  False  \n",
      "14  child       False  NaN  Southampton    no   True  \n",
      "44444444444444444444444444\n",
      "\n",
      "Passengers with missing age or fare > 200:\n",
      "    survived  pclass     sex   age  sibsp  parch      fare embarked   class  \\\n",
      "5          0       3    male   NaN      0      0    8.4583        Q   Third   \n",
      "17         1       2    male   NaN      0      0   13.0000        S  Second   \n",
      "19         1       3  female   NaN      0      0    7.2250        C   Third   \n",
      "26         0       3    male   NaN      0      0    7.2250        C   Third   \n",
      "27         0       1    male  19.0      3      2  263.0000        S   First   \n",
      "\n",
      "      who  adult_male deck  embark_town alive  alone  \n",
      "5     man        True  NaN   Queenstown    no   True  \n",
      "17    man        True  NaN  Southampton   yes   True  \n",
      "19  woman       False  NaN    Cherbourg   yes   True  \n",
      "26    man        True  NaN    Cherbourg    no   True  \n",
      "27    man        True    C  Southampton    no  False  \n",
      "555555555555555555555555555\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "print(df.head())\n",
    "\n",
    "# 1. Passengers who are female and survived\n",
    "female_survivors = df[(df['sex'] == 'female') & (df['survived'] == 1)]\n",
    "print(\"\\nFemale survivors:\")\n",
    "print(female_survivors.head())\n",
    "print(\"11111111111111111111111111\")\n",
    "\n",
    "\n",
    "# 2. Passengers who are either in first class OR over 60 years old\n",
    "first_class_or_elderly = df[(df['pclass'] == 1) | (df['age'] > 60)]\n",
    "print(\"\\nFirst class or elderly passengers:\")\n",
    "print(first_class_or_elderly.head())\n",
    "print(\"22222222222222222222222222\")\n",
    "\n",
    "# 3. Male passengers under 18 who did not survive\n",
    "young_male_non_survivors = df[(df['sex'] == 'male') & (df['age'] < 18) & (df['survived'] == 0)]\n",
    "print(\"\\nYoung male non-survivors:\")\n",
    "print(young_male_non_survivors.head())\n",
    "print(\"3333333333333333333333333333333333\")\n",
    "\n",
    "# 4. Females in 2nd or 3rd class\n",
    "female_in_2nd_3rd = df[(df['sex'] == 'female') & ((df['pclass'] == 2) | (df['pclass'] == 3))]\n",
    "print(\"\\nFemales in 2nd or 3rd class:\")\n",
    "print(female_in_2nd_3rd.head())\n",
    "print(\"44444444444444444444444444\")\n",
    "\n",
    "# 5. Passengers with missing age or fare > 200\n",
    "missing_age_or_expensive_fare = df[(df['age'].isnull()) | (df['fare'] > 200)]\n",
    "print(\"\\nPassengers with missing age or fare > 200:\")\n",
    "print(missing_age_or_expensive_fare.head())\n",
    "print(\"555555555555555555555555555\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df46a624-d6ae-4685-8e1c-9e9769c47e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
      "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
      "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
      "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
      "9       14.78  3.23    Male     No  Sun  Dinner     2\n",
      "0000000000000000000000000\n",
      "\n",
      "1. Tipped more than 20% of total bill:\n",
      "    total_bill   tip     sex smoker  day    time  size  tip_percent\n",
      "6         8.77  2.00    Male     No  Sun  Dinner     2    22.805017\n",
      "9        14.78  3.23    Male     No  Sun  Dinner     2    21.853857\n",
      "14       14.83  3.02  Female     No  Sun  Dinner     2    20.364127\n",
      "17       16.29  3.71    Male     No  Sun  Dinner     3    22.774708\n",
      "18       16.97  3.50  Female     No  Sun  Dinner     3    20.624632\n",
      "111111111111111111111111111\n",
      "\n",
      "2. Lunch time male customers with total bill between $15 and $30:\n",
      "    total_bill   tip   sex smoker   day   time  size  tip_percent\n",
      "77       27.20  4.00  Male     No  Thur  Lunch     4    14.705882\n",
      "78       22.76  3.00  Male     No  Thur  Lunch     2    13.181019\n",
      "79       17.29  2.71  Male     No  Thur  Lunch     2    15.673800\n",
      "80       19.44  3.00  Male    Yes  Thur  Lunch     2    15.432099\n",
      "81       16.66  3.40  Male     No  Thur  Lunch     2    20.408163\n",
      "2222222222222222222222222222\n",
      "\n",
      "3. Female smokers on weekend who tipped over $4:\n",
      "     total_bill  tip     sex smoker  day    time  size  tip_percent\n",
      "73        25.28  5.0  Female    Yes  Sat  Dinner     2    19.778481\n",
      "214       28.17  6.5  Female    Yes  Sat  Dinner     3    23.074192\n",
      "33333333333333333333333333\n",
      "\n",
      "4. Large tables (>=4) but low average tip per person (<$1.5):\n",
      "    total_bill   tip     sex smoker  day    time  size  tip_percent  \\\n",
      "4        24.59  3.61  Female     No  Sun  Dinner     4    14.680765   \n",
      "5        25.29  4.71    Male     No  Sun  Dinner     4    18.623962   \n",
      "7        26.88  3.12    Male     No  Sun  Dinner     4    11.607143   \n",
      "11       35.26  5.00  Female     No  Sun  Dinner     4    14.180374   \n",
      "13       18.43  3.00    Male     No  Sun  Dinner     4    16.277808   \n",
      "\n",
      "    tip_per_person  \n",
      "4           0.9025  \n",
      "5           1.1775  \n",
      "7           0.7800  \n",
      "11          1.2500  \n",
      "13          0.7500  \n",
      "444444444444444444444444\n",
      "\n",
      "5. Bills ending in .99:\n",
      "   total_bill   tip     sex smoker  day    time  size  tip_percent  \\\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2     5.944673   \n",
      "\n",
      "   tip_per_person  \n",
      "0           0.505  \n"
     ]
    }
   ],
   "source": [
    "# tips_filtering_examples.py\n",
    "\n",
    "# Load the tips dataset\n",
    "df = sns.load_dataset(\"tips\")\n",
    "print(df.head(10))\n",
    "print(\"0000000000000000000000000\")\n",
    "\n",
    "# 1. Filter: Customers who tipped more than 20% of their total bill\n",
    "df['tip_percent'] = (df['tip'] / df['total_bill']) * 100\n",
    "generous_tippers = df[df['tip_percent'] > 20]\n",
    "print(\"\\n1. Tipped more than 20% of total bill:\")\n",
    "print(generous_tippers.head())\n",
    "print(\"111111111111111111111111111\")\n",
    "\n",
    "# 2. Filter: Lunch time male customers with total bill between $15 and $30\n",
    "lunch_males = df[(df['time'] == 'Lunch') & (df['sex'] == 'Male') & (df['total_bill'].between(15, 30))]\n",
    "print(\"\\n2. Lunch time male customers with total bill between $15 and $30:\")\n",
    "print(lunch_males.head())\n",
    "print(\"2222222222222222222222222222\")\n",
    "\n",
    "# 3. Filter: Female smokers who dined on weekends and gave tips over $4\n",
    "female_weekend_smokers = df[\n",
    "    (df['sex'] == 'Female') &\n",
    "    (df['smoker'] == 'Yes') &\n",
    "    (df['day'].isin(['Sat', 'Sun'])) &\n",
    "    (df['tip'] > 4)\n",
    "]\n",
    "print(\"\\n3. Female smokers on weekend who tipped over $4:\")\n",
    "print(female_weekend_smokers.head())\n",
    "print(\"33333333333333333333333333\")\n",
    "\n",
    "# 4. Filter: Tables with size >= 4 but average tip per person < $1.5\n",
    "df['tip_per_person'] = df['tip'] / df['size']\n",
    "low_tip_big_tables = df[(df['size'] >= 4) & (df['tip_per_person'] < 1.5)]\n",
    "print(\"\\n4. Large tables (>=4) but low average tip per person (<$1.5):\")\n",
    "print(low_tip_big_tables.head())\n",
    "print(\"444444444444444444444444\")\n",
    "\n",
    "# 5. Filter: Bills where the cents value is close to 0.99 (i.e., total_bill ends in .99)\n",
    "rounded_bills = df[df['total_bill'].apply(lambda x: str(x).endswith('99'))]\n",
    "print(\"\\n5. Bills ending in .99:\")\n",
    "print(rounded_bills.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948c0b76-481f-4670-ab8e-542fbeca3a46",
   "metadata": {},
   "source": [
    "###  groupby and aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd39221-25f9-4c17-a228-11d791d1ed5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "   Department Employee  Salary  Experience Region\n",
      "0         HR    Rahim   60000           2   East\n",
      "1         IT  Vanessa   75000           5   West\n",
      "2    Finance     Cory   82000           7   East\n",
      "3         HR    David   58000           3   West\n",
      "4         IT     Neha   79000           4   East\n",
      "5    Finance    Frank   91000           9   West\n",
      "6         HR    Grace   62000           2   East\n",
      "7         IT    Helen   73000           6   East\n",
      "8    Finance      Ian   88000           8   West\n",
      "00000000000000000000000000\n",
      "Department\n",
      "Finance    3\n",
      "HR         3\n",
      "IT         3\n",
      "dtype: int64\n",
      "1111111111111111111111111111\n",
      "            Employee  Salary  Experience  Region\n",
      "Department                                      \n",
      "Finance            3       3           3       3\n",
      "HR                 3       3           3       3\n",
      "IT                 3       3           3       3\n",
      "1111111111111111111111111111\n",
      "Region\n",
      "East    5\n",
      "West    4\n",
      "dtype: int64\n",
      "22222222222222222222222\n",
      "Department  Region\n",
      "Finance     East      1\n",
      "            West      2\n",
      "HR          East      2\n",
      "            West      1\n",
      "IT          East      2\n",
      "            West      1\n",
      "dtype: int64\n",
      "33333333333333333333333333\n",
      "\n",
      "Average Salary by Department:\n",
      " Department\n",
      "Finance    87000.000000\n",
      "HR         60000.000000\n",
      "IT         75666.666667\n",
      "Name: Salary, dtype: float64\n",
      "44444444444444444444444444\n",
      "\n",
      "Total Experience by Department:\n",
      " Department\n",
      "Finance    24\n",
      "HR          7\n",
      "IT         15\n",
      "Name: Experience, dtype: int64\n",
      "555555555555555555555555555\n",
      "\n",
      "Average Salary by Department and Region:\n",
      " Department  Region\n",
      "Finance     East      82000.0\n",
      "            West      89500.0\n",
      "HR          East      61000.0\n",
      "            West      58000.0\n",
      "IT          East      76000.0\n",
      "            West      75000.0\n",
      "Name: Salary, dtype: float64\n",
      "\n",
      "Iterating through groups:\n",
      "\n",
      "Department: Finance\n",
      "  Department Employee  Salary  Experience Region\n",
      "2    Finance     Cory   82000           7   East\n",
      "5    Finance    Frank   91000           9   West\n",
      "8    Finance      Ian   88000           8   West\n",
      "\n",
      "Department: HR\n",
      "  Department Employee  Salary  Experience Region\n",
      "0         HR    Rahim   60000           2   East\n",
      "3         HR    David   58000           3   West\n",
      "6         HR    Grace   62000           2   East\n",
      "\n",
      "Department: IT\n",
      "  Department Employee  Salary  Experience Region\n",
      "1         IT  Vanessa   75000           5   West\n",
      "4         IT     Neha   79000           4   East\n",
      "7         IT    Helen   73000           6   East\n",
      "\n",
      "Multiple Aggregations by Department:\n",
      "                   Salary               Experience      \n",
      "                    mean    max    min       mean count\n",
      "Department                                             \n",
      "Finance     87000.000000  91000  82000   8.000000     3\n",
      "HR          60000.000000  62000  58000   2.333333     3\n",
      "IT          75666.666667  79000  73000   5.000000     3\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "# Sample employee data\n",
    "data = {\n",
    "    'Department': ['HR', 'IT', 'Finance', 'HR', 'IT', 'Finance', 'HR', 'IT', 'Finance'],\n",
    "    'Employee': ['Rahim', 'Vanessa', 'Cory', 'David', 'Neha', 'Frank', 'Grace', 'Helen', 'Ian'],\n",
    "    'Salary': [60000, 75000, 82000, 58000, 79000, 91000, 62000, 73000, 88000],\n",
    "    'Experience': [2, 5, 7, 3, 4, 9, 2, 6, 8],\n",
    "    'Region' : ['East', 'West', 'East', 'West', 'East', 'West', 'East', 'East', 'West']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Data:\\n\", df)\n",
    "print(\"00000000000000000000000000\")\n",
    "\n",
    "# Group by Department\n",
    "grouped_counts = df.groupby(['Department',]).size() # size() total rows in each group: Includes NaN values\n",
    "print(grouped_counts)\n",
    "print(\"1111111111111111111111111111\")\n",
    "grouped_counts = df.groupby(['Department',]).count() # count() would give total of non-null in each group\n",
    "print(grouped_counts)\n",
    "print(\"1111111111111111111111111111\")\n",
    "\n",
    "\n",
    "# Group by Region\n",
    "grouped_counts = df.groupby(['Region',]).size()\n",
    "print(grouped_counts)\n",
    "print(\"22222222222222222222222\")\n",
    "\n",
    "# Group by Department and Region\n",
    "grouped_counts = df.groupby(['Department', 'Region']).size()\n",
    "print(grouped_counts)\n",
    "print(\"33333333333333333333333333\")\n",
    "\n",
    "# Group by department and calculate average salary\n",
    "avg_salary = df.groupby('Department')['Salary'].mean()\n",
    "print(\"\\nAverage Salary by Department:\\n\", avg_salary)\n",
    "print(\"44444444444444444444444444\")\n",
    "\n",
    "\n",
    "# Group by department and calculate total experience\n",
    "total_exp = df.groupby('Department')['Experience'].sum()\n",
    "print(\"\\nTotal Experience by Department:\\n\", total_exp)\n",
    "print(\"555555555555555555555555555\")\n",
    "\n",
    "\n",
    "# Group by multiple columns\n",
    "grouped = df.groupby(['Department', 'Region'])['Salary'].mean()\n",
    "print(\"\\nAverage Salary by Department and Region:\\n\", grouped)\n",
    "\n",
    "\n",
    "# (SKIP: OPTIONAL)Get the group for a particular key\n",
    "# hr_group = df.groupby('Department').get_group('HR')\n",
    "# print(\"\\nAll Employees in HR:\\n\", hr_group)\n",
    "\n",
    "\n",
    "# Iterate over groups\n",
    "print(\"\\nIterating through groups:\")\n",
    "grouped = df.groupby('Department')\n",
    "for name, group in grouped:\n",
    "    print(f\"\\nDepartment: {name}\")\n",
    "    print(group)\n",
    "\n",
    "#### Aggregation\n",
    "# (SKIP: OPTIONAL)Group by department and get multiple stats\n",
    "multi_stats = df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'max', 'min'],\n",
    "    'Experience': ['mean', 'count']\n",
    "})\n",
    "print(\"\\nMultiple Aggregations by Department:\\n\", multi_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed2158ee-e9b9-4514-9a2c-bc07e938415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "111111111111111111111111\n",
      "        PassengerId  Survived  Pclass  Name  Age  SibSp  Parch  Ticket  Fare  \\\n",
      "Sex                                                                            \n",
      "female          314       314     314   314  261    314    314     314   314   \n",
      "male            577       577     577   577  453    577    577     577   577   \n",
      "\n",
      "        Cabin  Embarked  \n",
      "Sex                      \n",
      "female     97       312  \n",
      "male      107       577  \n",
      "222222222222222222222222\n",
      "Sex\n",
      "female    44.479818\n",
      "male      25.523893\n",
      "Name: Fare, dtype: float64\n",
      "333333333333333333333333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Fare</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>female</th>\n",
       "      <td>44.479818</td>\n",
       "      <td>23.0</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>6.75</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>male</th>\n",
       "      <td>25.523893</td>\n",
       "      <td>10.5</td>\n",
       "      <td>512.3292</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fare                         Survived\n",
       "             mean median       max   min      mean\n",
       "Sex                                               \n",
       "female  44.479818   23.0  512.3292  6.75  0.742038\n",
       "male    25.523893   10.5  512.3292  0.00  0.188908"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 2\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/ash322ash422/tut_pandas_numpy/refs/heads/master/titanic.csv', sep=',')\n",
    "print(df.head(5))\n",
    "print(\"111111111111111111111111\")\n",
    "\n",
    "print(df.groupby('Sex').count())\n",
    "print(\"222222222222222222222222\")\n",
    "\n",
    "print(df.groupby('Sex')['Fare'].mean()) # .mean() for 'Fare' gives the average fare paid by male vs. female passengers.\n",
    "print(\"333333333333333333333333\")\n",
    "\n",
    "########### Aggregation #####################\n",
    "df.groupby('Sex').agg({\n",
    "    'Fare': ['mean', 'median', 'max', 'min'],\n",
    "    'Survived': 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "433f6c84-fd73-4cbc-95fe-8b030c47bf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
      "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
      "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
      "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
      "9       14.78  3.23    Male     No  Sun  Dinner     2\n",
      "00000000000000000000\n",
      "day\n",
      "Thur    62\n",
      "Fri     19\n",
      "Sat     87\n",
      "Sun     76\n",
      "dtype: int64\n",
      "1111111111111111111111\n",
      "time\n",
      "Lunch      68\n",
      "Dinner    176\n",
      "dtype: int64\n",
      "222222222222222222222\n",
      "day   time  \n",
      "Thur  Lunch     61\n",
      "      Dinner     1\n",
      "Fri   Lunch      7\n",
      "      Dinner    12\n",
      "Sat   Lunch      0\n",
      "      Dinner    87\n",
      "Sun   Lunch      0\n",
      "      Dinner    76\n",
      "dtype: int64\n",
      "33333333333333333333\n",
      "             count      mean       std   min     25%   50%    75%    max\n",
      "day  time                                                               \n",
      "Thur Lunch    61.0  2.767705  1.250162  1.25  2.0000  2.30  3.400   6.70\n",
      "     Dinner    1.0  3.000000       NaN  3.00  3.0000  3.00  3.000   3.00\n",
      "Fri  Lunch     7.0  2.382857  0.662966  1.58  1.9600  2.20  2.750   3.48\n",
      "     Dinner   12.0  2.940000  1.156098  1.00  2.2500  3.00  3.625   4.73\n",
      "Sat  Dinner   87.0  2.993103  1.631014  1.00  2.0000  2.75  3.370  10.00\n",
      "Sun  Dinner   76.0  3.255132  1.234880  1.01  2.0375  3.15  4.000   6.50\n",
      "44444444444444444444444444\n",
      "    Day   Avg_Tip  Max_Tip  Min_Tip  Count\n",
      "0  Thur  2.771452     6.70     1.25     62\n",
      "1   Fri  2.734737     4.73     1.00     19\n",
      "2   Sat  2.993103    10.00     1.00     87\n",
      "3   Sun  3.255132     6.50     1.01     76\n"
     ]
    }
   ],
   "source": [
    "# example 3\n",
    "import seaborn as sns\n",
    "\n",
    "df = sns.load_dataset(\"tips\")\n",
    "print(df.head(10))\n",
    "print(\"00000000000000000000\")\n",
    "\n",
    "print(df.groupby(['day'], observed=False).size())\n",
    "print(\"1111111111111111111111\")\n",
    "\n",
    "print(df.groupby(['time'], observed=False).size())\n",
    "print(\"222222222222222222222\")\n",
    "\n",
    "# Group by 'day' and 'time' to see how many entries there are\n",
    "print(df.groupby(['day', 'time'], observed=False).size())\n",
    "print(\"33333333333333333333\")\n",
    "\n",
    "print(df.groupby(['day', 'time'], observed=False)['tip'].describe())\n",
    "print(\"44444444444444444444444444\")\n",
    "\n",
    "#################################################\n",
    "########### Aggregation #####################\n",
    "tip_by_day = df.groupby('day').agg({\n",
    "    'tip': ['mean', 'max', 'min', 'count']\n",
    "}).reset_index()\n",
    "\n",
    "tip_by_day.columns = ['Day', 'Avg_Tip', 'Max_Tip', 'Min_Tip', 'Count']\n",
    "print(tip_by_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73460c02-f62d-489c-bdc3-655da663d6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   total_bill   tip     sex smoker  day    time  size\n",
      "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
      "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
      "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
      "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
      "4       24.59  3.61  Female     No  Sun  Dinner     4\n",
      "5       25.29  4.71    Male     No  Sun  Dinner     4\n",
      "6        8.77  2.00    Male     No  Sun  Dinner     2\n",
      "7       26.88  3.12    Male     No  Sun  Dinner     4\n",
      "8       15.04  1.96    Male     No  Sun  Dinner     2\n",
      "9       14.78  3.23    Male     No  Sun  Dinner     2\n",
      "\n",
      "1. Average tip by day:\n",
      "day\n",
      "Thur    2.771452\n",
      "Fri     2.734737\n",
      "Sat     2.993103\n",
      "Sun     3.255132\n",
      "Name: tip, dtype: float64\n",
      "1111111111111111111111\n",
      "\n",
      "2. Total bill and tip (Smoker vs Non-Smoker):\n",
      "        total_bill     tip\n",
      "smoker                    \n",
      "Yes        1930.34  279.81\n",
      "No         2897.43  451.77\n",
      "\n",
      "3. Average tip percentage by gender:\n",
      "sex\n",
      "Male      0.157651\n",
      "Female    0.166491\n",
      "Name: tip_pct, dtype: float64\n",
      "\n",
      "4. Median tip by day and time:\n",
      "day   time  \n",
      "Thur  Lunch     2.30\n",
      "      Dinner    3.00\n",
      "Fri   Lunch     2.20\n",
      "      Dinner    3.00\n",
      "Sat   Lunch      NaN\n",
      "      Dinner    2.75\n",
      "Sun   Lunch      NaN\n",
      "      Dinner    3.15\n",
      "Name: tip, dtype: float64\n",
      "\n",
      "5. Stats by table size (count, average total bill, max tip):\n",
      "      total_bill    tip  count\n",
      "size                          \n",
      "1       7.242500   1.92      4\n",
      "2      16.448013   5.85    156\n",
      "3      23.277632  10.00     38\n",
      "4      28.613514   9.00     37\n",
      "5      30.068000   5.14      5\n",
      "6      34.830000   6.70      4\n"
     ]
    }
   ],
   "source": [
    "# example 4\n",
    "# tips_groupby_examples.py\n",
    "\n",
    "# Load the tips dataset\n",
    "df = sns.load_dataset(\"tips\")\n",
    "print(df.head(10))\n",
    "\n",
    "# 1. Average tip by day\n",
    "avg_tip_by_day = df.groupby(\"day\")[\"tip\"].mean()\n",
    "print(\"\\n1. Average tip by day:\")\n",
    "print(avg_tip_by_day)\n",
    "print(\"1111111111111111111111\")\n",
    "\n",
    "# 2. Total bill and tip by smoker vs non-smoker\n",
    "total_by_smoker = df.groupby(\"smoker\")[[\"total_bill\", \"tip\"]].sum()\n",
    "print(\"\\n2. Total bill and tip (Smoker vs Non-Smoker):\")\n",
    "print(total_by_smoker)\n",
    "\n",
    "# 3. Tip percentage by gender\n",
    "df['tip_pct'] = df['tip'] / df['total_bill']\n",
    "avg_tip_pct_by_sex = df.groupby(\"sex\")[\"tip_pct\"].mean()\n",
    "print(\"\\n3. Average tip percentage by gender:\")\n",
    "print(avg_tip_pct_by_sex)\n",
    "\n",
    "# 4. Median tip by day and time (multi-index group)\n",
    "median_tip_by_day_time = df.groupby([\"day\", \"time\"])[\"tip\"].median()\n",
    "print(\"\\n4. Median tip by day and time:\")\n",
    "print(median_tip_by_day_time)\n",
    "\n",
    "\n",
    "### Aggregation\n",
    "# 5. Group by table size and find count, average total_bill, and max tip\n",
    "stats_by_size = df.groupby(\"size\").agg({\n",
    "    \"total_bill\": \"mean\",\n",
    "    \"tip\": \"max\",\n",
    "    \"sex\": \"count\"  # Just to see how many entries per group\n",
    "}).rename(columns={\"sex\": \"count\"})\n",
    "print(\"\\n5. Stats by table size (count, average total bill, max tip):\")\n",
    "print(stats_by_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a57c527-8dca-4ffc-b197-70e0698c678c",
   "metadata": {},
   "source": [
    "## [concat](https://pandas.pydata.org/docs/user_guide/merging.html)\n",
    "Taken from a good source: [concat](https://pandas.pydata.org/docs/user_guide/merging.html) Look here for visual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b1ef3-28bd-4f3b-abd7-e87823ea0594",
   "metadata": {},
   "source": [
    "[concat](https://pandas.pydata.org/docs/user_guide/merging.html#concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d20336b-68ba-4a31-9eff-ee17a3c1a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame(\n",
    " {\n",
    " \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    " \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    " \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    " \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    " },\n",
    " index=[0, 1, 2, 3],\n",
    ")\n",
    "\n",
    "df2 = pd.DataFrame(\n",
    " {\n",
    " \"A\": [\"A4\", \"A5\", \"A6\", \"A7\"],\n",
    " \"B\": [\"B4\", \"B5\", \"B6\", \"B7\"],\n",
    " \"C\": [\"C4\", \"C5\", \"C6\", \"C7\"],\n",
    " \"D\": [\"D4\", \"D5\", \"D6\", \"D7\"],\n",
    " },\n",
    " index=[4, 5, 6, 7],\n",
    " )\n",
    "\n",
    "df3 = pd.DataFrame(\n",
    " {\n",
    " \"A\": [\"A8\", \"A9\", \"A10\", \"A11\"],\n",
    " \"B\": [\"B8\", \"B9\", \"B10\", \"B11\"],\n",
    " \"C\": [\"C8\", \"C9\", \"C10\", \"C11\"],\n",
    " \"D\": [\"D8\", \"D9\", \"D10\", \"D11\"],\n",
    " },\n",
    " index=[8, 9, 10, 11],\n",
    ")\n",
    "\n",
    "frames = [df1, df2, df3]\n",
    "\n",
    "result =  pd.concat(frames)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5e6e26a-b296-4a20-b305-625c7e7dbfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    B    D    F\n",
      "0   A0   B0   C0   D0  NaN  NaN  NaN\n",
      "1   A1   B1   C1   D1  NaN  NaN  NaN\n",
      "2   A2   B2   C2   D2   B2   D2   F2\n",
      "3   A3   B3   C3   D3   B3   D3   F3\n",
      "6  NaN  NaN  NaN  NaN   B6   D6   F6\n",
      "7  NaN  NaN  NaN  NaN   B7   D7   F7\n"
     ]
    }
   ],
   "source": [
    "# Joining logic of the resulting axis\n",
    "df4 = pd.DataFrame(\n",
    "   {\n",
    "       \"B\": [\"B2\", \"B3\", \"B6\", \"B7\"],\n",
    "       \"D\": [\"D2\", \"D3\", \"D6\", \"D7\"],\n",
    "       \"F\": [\"F2\", \"F3\", \"F6\", \"F7\"],\n",
    "   },\n",
    "   index=[2, 3, 6, 7],\n",
    ")\n",
    "result = pd.concat([df1, df4], axis=1)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fb4d5ee-f6ef-4f54-8f49-67c5ac84729b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n"
     ]
    }
   ],
   "source": [
    "# join='inner' takes the intersection of the axis values\n",
    "result = pd.concat([df1, df4], axis=1, join=\"inner\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "876a8c9b-dd65-4ba6-b6ba-7e0f478e62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D    B    D    F\n",
      "0  A0  B0  C0  D0  NaN  NaN  NaN\n",
      "1  A1  B1  C1  D1  NaN  NaN  NaN\n",
      "2  A2  B2  C2  D2   B2   D2   F2\n",
      "3  A3  B3  C3  D3   B3   D3   F3\n"
     ]
    }
   ],
   "source": [
    "# To perform an effective “left” join using the exact index from the original DataFrame, result can be reindexed.\n",
    "result = pd.concat([df1, df4], axis=1).reindex(df1.index)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa7cc137-6d34-4b0b-ba1f-15dcc9058762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C   D    F\n",
      "0   A0  B0   C0  D0  NaN\n",
      "1   A1  B1   C1  D1  NaN\n",
      "2   A2  B2   C2  D2  NaN\n",
      "3   A3  B3   C3  D3  NaN\n",
      "4  NaN  B2  NaN  D2   F2\n",
      "5  NaN  B3  NaN  D3   F3\n",
      "6  NaN  B6  NaN  D6   F6\n",
      "7  NaN  B7  NaN  D7   F7\n"
     ]
    }
   ],
   "source": [
    "# Ignoring indexes on the concatenation axis\n",
    "# For DataFrame objects which don’t have a meaningful index, the ignore_index ignores overlapping indexes.\n",
    "\n",
    "result = pd.concat([df1, df4], ignore_index=True, sort=False)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b705284-ce2e-47e0-8409-89cbacfa1414",
   "metadata": {},
   "source": [
    "## merge: [merge](https://pandas.pydata.org/docs/user_guide/merging.html#merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4009f868-3a87-4b17-a12f-50569b2c70c7",
   "metadata": {},
   "source": [
    "For a **many-to-many** join, if a key combination appears\n",
    "more than once in both tables, the :class:`DataFrame` will have the **Cartesian\n",
    "product** of the associated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8a9d489-d4b4-4b6d-b9db-1bf1f2aae6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  key   A   B   C   D\n",
      "0  K0  A0  B0  C0  D0\n",
      "1  K1  A1  B1  C1  D1\n",
      "2  K2  A2  B2  C2  D2\n",
      "3  K3  A3  B3  C3  D3\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame(\n",
    "   {\n",
    "       \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "       \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"],\n",
    "       \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\n",
    "   }\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "   {\n",
    "       \"key\": [\"K0\", \"K1\", \"K2\", \"K3\"],\n",
    "       \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"],\n",
    "       \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\n",
    "   }\n",
    ")\n",
    "result = pd.merge(left, right, on=\"key\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c6562-769c-4a3c-b94a-ea2c1f8aa4cc",
   "metadata": {},
   "source": [
    "## Join: [join](https://pandas.pydata.org/docs/user_guide/merging.html#dataframe-join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51afe027-9799-47ac-b701-5ca4bf0c214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A   B    C    D\n",
      "K0  A0  B0   C0   D0\n",
      "K1  A1  B1  NaN  NaN\n",
      "K2  A2  B2   C2   D2\n"
     ]
    }
   ],
   "source": [
    "left = pd.DataFrame(\n",
    " {\"A\": [\"A0\", \"A1\", \"A2\"], \"B\": [\"B0\", \"B1\", \"B2\"]}, index=[\"K0\", \"K1\", \"K2\"]\n",
    ")\n",
    "\n",
    "right = pd.DataFrame(\n",
    "   {\"C\": [\"C0\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D2\", \"D3\"]}, index=[\"K0\", \"K2\", \"K3\"]\n",
    " )\n",
    "\n",
    "result = left.join(right)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d36537a9-84ae-49c3-ab37-5d903566d516",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ignore the rest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
